{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe637a-e6d7-42e5-aafa-88baa4d901c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2fa1a-1d13-464e-9da8-e9b317027e66",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceddd65-80dc-4696-82a8-8927030b04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('PyTorch is using', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70f808-1302-43c9-baec-466470dd8637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1aa1b-8260-4910-9748-8a2ccf654b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset related\n",
    "dataset_name = \"MNIST\"\n",
    "resize_h, resize_w = 28, 28\n",
    "\n",
    "# dataloader related\n",
    "batch_size = 36\n",
    "num_workers = 8\n",
    "prefetch_factor = 4\n",
    "\n",
    "# model related\n",
    "num_layers = 2\n",
    "num_z = 1024\n",
    "\n",
    "# training related\n",
    "epochs = 30\n",
    "init_lr = 1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9b9ae-72e7-44ba-bcdd-1c4b2bd528a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881d666-ac75-42d0-a1cb-e782a6470a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,\n",
    "          model, train_loader,\n",
    "          criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = criterion(recon_batch, data, mu, logvar)\n",
    "        train_loss += loss.item() / len(train_loader.dataset)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return train_loss\n",
    "\n",
    "def reconstruct(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "\n",
    "            n = min(data.shape[0], 8)\n",
    "            samples = data[:n].cpu().numpy()\n",
    "            recons = recon_batch[:n].cpu().numpy()\n",
    "            \n",
    "            break\n",
    "\n",
    "    return samples, recons\n",
    "\n",
    "def test(epoch,\n",
    "         model, test_loader,\n",
    "         criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            \n",
    "            loss = criterion(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item() / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c428b4-5372-418d-a126-3fada8d8d3fc",
   "metadata": {},
   "source": [
    "# Visualization related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6804b-c85a-4ced-bc32-59c3dc9cd753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_rgb(sample):\n",
    "    r = sample[0]\n",
    "    g = sample[1]\n",
    "    b = sample[2]\n",
    "    rgb = (np.dstack((r,g,b)) * 255.999) .astype(np.uint8)\n",
    "    return rgb\n",
    "\n",
    "def visualize_imgs(samples, recons):\n",
    "    (n,c,h,w) = samples.shape\n",
    "    plt.figure(figsize=(28, 8))\n",
    "    \n",
    "    if (c == 3):\n",
    "        for i in range(n):\n",
    "            plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(to_rgb(samples[i]))\n",
    "\n",
    "            plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(to_rgb(recons[i]))\n",
    "        plt.show()\n",
    "    elif (c == 1):\n",
    "        for i in range(n):\n",
    "            plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(samples[i].reshape(28, 28), cmap='gray_r')\n",
    "\n",
    "            plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(recons[i].reshape(28, 28), cmap='gray_r')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ed6bb-6479-44f2-a09d-f261aec341e5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46946d01-d1ef-4a0c-bb4d-698a3ad04a2a",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607dd2f-0e14-4482-865a-1b2b1ca8b510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(resize_h, resize_w)),\n",
    "    transforms.ToTensor(),    \n",
    "])\n",
    "dataset = CustomDataset(dataset_name=dataset_name, transforms=transforms)\n",
    "train_loader = dataset.get_dataloader(is_train=True,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      prefetch_factor=prefetch_factor)\n",
    "test_loader = dataset.get_dataloader(is_train=False,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     prefetch_factor=prefetch_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2728646-498b-4a4e-b117-10d4f371daf5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ca2a0-3f88-4a8c-b1f5-e41ca0def804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = resize_h * resize_w\n",
    "\n",
    "layers = [int(input_dim / (2 ** i)) for i in range(num_layers)]\n",
    "model = VAE(layers, num_z).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = ELBO(input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d08857-f922-4e84-9ec5-b091585c1dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learn\n",
    "last_loss = torch.finfo(torch.float32).max\n",
    "total_time = 0\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # generate and visualize\n",
    "    samples, recons = reconstruct(model, test_loader)\n",
    "    visualize_imgs(samples, recons)\n",
    "    \n",
    "    # train\n",
    "    start_time = time.time()\n",
    "    loss = train(epoch,\n",
    "                 model, train_loader,\n",
    "                 criterion, optimizer)\n",
    "    end_time = time.time()\n",
    "    train_losses.append(loss)\n",
    "    dt = end_time - start_time\n",
    "    total_time += dt\n",
    "\n",
    "    # test\n",
    "    loss = test(epoch,\n",
    "                model, test_loader,\n",
    "                criterion)\n",
    "    test_losses.append(loss)\n",
    "    \n",
    "    print(f'Epoch {epoch} / {epochs}: {loss:.2f} in {dt:.2f} secs', '*' if loss < last_loss else '')\n",
    "\n",
    "print('Train loss:', train_losses)\n",
    "print('Test loss:', test_losses)\n",
    "print(f'Average {total_time / epochs:.2f} secs per epoch consumed')\n",
    "print(f'Total {total_time:.2f} secs consumed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe3c65-0295-4416-a45a-e6e93a06fc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afe0da-cd6f-46c6-aba1-7a37f7e3874a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
